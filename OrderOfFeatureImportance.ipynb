{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZPU8D7Z6Gx9kNRprt1cnT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulsemedShalo/AbdulsemedShalo/blob/main/OrderOfFeatureImportance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE_jK9OMt_Ug",
        "outputId": "da8ab333-5b2a-417a-e8e3-8528d52faf8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error: 0.0\n",
            "Accuracy of the model : 1.0\n",
            "Features in order of importance:\n",
            "Label\n",
            "Max_Packet_Length\n",
            "Fwd_Packet_Length_Max\n",
            "Flow_Bytes_Sec\n",
            "Flow_Packets_Sec\n",
            "Packet_Length_Std\n",
            "Packet_Length_Variance\n",
            "Flow_IAT_Max\n",
            "Fwd_IAT_Max\n",
            "Subflow_Fwd_Bytes\n",
            "Fwd_Packet_Length_Std\n",
            "min_seg_size_forward\n",
            "Bwd_Packets_Sec\n",
            "Init_Win_bytes_backward\n",
            "Average_Packet_Size\n",
            "Packet_Length_Mean\n",
            "Fwd_IAT_Total\n",
            "Flow_IAT_Std\n",
            "Fwd_IAT_Std\n",
            "Fwd_Packet_Length_Mean\n",
            "Avg_Fwd_Segment_Size\n",
            "Fwd_Header_Length\n",
            "Fwd_IAT_Mean\n",
            "Idle_Max\n",
            "Flow_IAT_Mean\n",
            "Idle_Mean\n",
            "Fwd_Packets_Sec\n",
            "Idle_Min\n",
            "Bwd_Header_Length\n",
            "Active_Min\n",
            "Bwd_Packet_Length_Mean\n",
            "Bwd_Packet_Length_Max\n",
            "Subflow_Bwd_Bytes\n",
            "Total_Length_of_Bwd_Packets\n",
            "Avg_Bwd_Segment_Size\n",
            "Subflow_Bwd_Packets\n",
            "Fwd_IAT_Min\n",
            "Flow_IAT_Min\n",
            "Idle_Std\n",
            "SYN_Flag_Count\n",
            "act_data_pkt_fwd\n",
            "Subflow_Fwd_Packets\n",
            "Active_Max\n",
            "Active_Mean\n",
            "Fwd_Packet_Length_Min\n",
            "Min_Packet_Length\n",
            "Bwd_IAT_Mean\n",
            "Bwd_IAT_Min\n",
            "Bwd_IAT_Total\n",
            "Init_Win_bytes_forward\n",
            "Bwd_IAT_Max\n",
            "Bwd_Packet_Length_Min\n",
            "Down_Up_Ratio\n",
            "Active_Std\n",
            "Bwd_IAT_Std\n",
            "Bwd_Packet_Length_Std\n",
            "Destination.Port\n",
            "Source.Port\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/AbdulsemedShalo/DDOS-Detection-and-Mitigation/main/trainer.csv')\n",
        "\n",
        "data = data.drop(\"Flow.ID\", axis=1)\n",
        "data = data.drop(\"Source.IP\", axis=1)\n",
        "data = data.drop(\"Destination.IP\", axis=1)\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, data[\"Label\"], test_size=0.2)\n",
        "\n",
        "# Transform the negative feature values to positive values\n",
        "features_positive = X_train.copy()\n",
        "features_positive[features_positive < 0] = 0\n",
        "\n",
        "# Create a logistic regression model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Re-fit the model to the transformed data\n",
        "model.fit(features_positive, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(features_positive)\n",
        "\n",
        "# Evaluate the model performance\n",
        "print('Mean absolute error:', np.mean(np.abs(predictions - y_train)))\n",
        "\n",
        "# Calculate the mutual information between each feature and the labels\n",
        "mi_scores = mutual_info_classif(X_train, y_train)\n",
        "\n",
        "# Sort the features by their mutual information scores\n",
        "sorted_features = np.argsort(mi_scores)\n",
        "\n",
        "# Print the features in order of importance\n",
        "print('Features in order of importance:')\n",
        "for i in sorted_features[::-1]:\n",
        "    print(data.columns[i])\n",
        "\n",
        "\n",
        "# [ Here below is the describtion for the upper line of code ]\n",
        "# The mutual information between two variables is a measure of how much information one variable provides about the other.\n",
        "# In this case, the mutual information between each feature and the labels measures how much information the feature provides about the class label.\n",
        "# The higher the mutual information score, the more important the feature is for predicting the class label.\n",
        "\n",
        "#The model.fit(features, labels) line fits the model to the training data.\n",
        "#The features_positive = features.copy() line creates a copy of the features.\n",
        "#The features_positive[features_positive < 0] = 0 line transforms the negative feature values in the copy to positive values.\n",
        "#The model.fit(features_positive, labels) line re-fits the model to the transformed data.\n",
        "#The predictions = model.predict(features_positive) line makes predictions on the test data using the transformed features.\n",
        "#The print('Mean absolute error:', np.mean(np.abs(predictions - labels))) line prints the mean absolute error of the model.\n"
      ]
    }
  ]
}